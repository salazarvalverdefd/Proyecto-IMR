# -*- coding: utf-8 -*-
"""Gabor + GLCM-template.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q7zntkR5MLSCQ0Jz7wJpKT7SfW9ENxe6

# **1.Conectamos Colab con Drive**
"""

from google.colab import drive
drive.mount('/content/drive')

import os
### Cambiar por nombre de la carpeta donde esta este codigo 
### Dentro de esta carpeta debe estar el dataset 
PATH_ORIGEN = "/content/drive/MyDrive/Proyectos-independientes/Proyecto-MINSA/Dataset/Clasificacion/HGG-LGG"
os.chdir(PATH_ORIGEN)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
from random import shuffle
import sys
import h5py
import utils
import math
from fractions import Fraction
from tqdm.auto import tqdm 
from skimage.feature import greycomatrix, greycoprops
import pandas as pd 
import time

sys.path.append(os.path.abspath(PATH_ORIGEN))

# Frame size  
img_size = 224

img_size_touple = (img_size, img_size)

# Number of channels (RGB)
num_channels = 3

# Flat frame size
img_size_flat = img_size * img_size * num_channels

# Number of classes for classification (HGG-LGG)
num_classes = 2

# Number of files to train
_num_files_train = 1

# Number of frames per video
_images_per_file = 155

# Number of frames per training set
_num_images_train = _num_files_train * _images_per_file

# Video extension
video_exts = ".mp4"

# Cambiar la ruta en donde estan los videos
in_dir = "/content/drive/MyDrive/Proyectos-independientes/Proyecto-MINSA/Dataset/Clasificacion/HGG-LGG/AVI"

"""# **2.Llamando funciones de Utils.py**"""

names, labels = utils.label_video_names(in_dir)

#print(names[0])
#print(len(names))

#print(labels[0])
#print(len(labels))

frames = utils.get_frames(in_dir, names[12])
#print(frames.shape)

#visible_frame = (frames*255).astype('uint8')

#img = visible_frame[80][:,:,2]
#plt.figure(1,figsize = (10,10))
#plt.imshow(img,cmap = 'gray')
#plt.show()

"""# **2.1.Preprocesamiento** """

# P1: Filtro LoG 
#blur = cv2.GaussianBlur(img,(3,3),0) 
#laplacian = cv2.Laplacian(blur,cv2.CV_8UC1)
#laplacian1 = laplacian/laplacian.max()

#plt.figure(1,figsize = (10,10))
#plt.imshow(laplacian,cmap = 'gray')
#plt.show()

# P2: Umbralizacion
"""aux = np.zeros((img.shape[0],img.shape[1]),dtype= np.uint8)
for i in range(img.shape[0]):
  for j in range(img.shape[1]):
    if img[i,j] != 0: 
      aux[i,j] = 1
    else:
      aux[i,j] = 0

plt.figure(1,figsize = (10,10))
plt.imshow(aux,cmap = 'gray')
plt.show()"""

# Contorno más grande
#cnts,_ = cv2.findContours(laplacian,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)
#cnts,_ = cv2.findContours(aux,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)
#contour_sizes = [(cv2.contourArea(cnt), cnt) for cnt in cnts]
#biggest_contour = max(contour_sizes, key=lambda x: x[0])[1]

# Coordenadas que encierran al contorno más grande 
#x,y,w,h = cv2.boundingRect(biggest_contour)
#print("Coordenadas: " + " \n x1: " + str(x) ," \n x2:" , str(x + w) , "\n y1: ", str(y) , "\n y2:", str(y + h))

# Cropped --> LoG
#crop = img[y:y+h,x:x+w]
#plt.figure(1,figsize = (10,10))
#plt.imshow(crop,cmap = "gray")
#plt.show()

#print(crop.shape)

# Cropped --> Umbralizacion
#crop = img[y:y+h,x:x+w]
#plt.figure(1,figsize = (10,10))
#plt.imshow(crop,cmap = "gray")
#plt.show()

#print(crop.shape)

def LoG(image):
  blur = cv2.GaussianBlur(image,(3,3),0)
  laplacian = cv2.Laplacian(blur,cv2.CV_8UC1) 

  cnts,_ = cv2.findContours(laplacian,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)
  contour_sizes = [(cv2.contourArea(cnt), cnt) for cnt in cnts]
  biggest_contour = max(contour_sizes, key=lambda x: x[0])[1]

  x,y,w,h = cv2.boundingRect(biggest_contour)
  crop = image[y:y+h,x:x+w]

  return crop

def cropped(image):

  aux = np.zeros((img.shape[0],img.shape[1]),dtype= np.uint8)

  for i in range(img.shape[0]):
    for j in range(img.shape[1]):
      if img[i,j] != 0: 
        aux[i,j] = 1
      else:
        aux[i,j] = 0
  
  cnts,_ = cv2.findContours(aux,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)
  contour_sizes = [(cv2.contourArea(cnt), cnt) for cnt in cnts]

  if len(contour_sizes) > 0:
    biggest_contour = max(contour_sizes, key=lambda x: x[0])[1]
    x,y,w,h = cv2.boundingRect(biggest_contour)
    crop = image[y:y+h,x:x+w] 

    return crop

#len(crop.shape)

"""# **3. Feature Extraction**

## **3.1.Transformada de Gabor**
"""

# Diccionario de parámetros 
thetas = np.arange(0, np.pi, np.pi/4) # range of theta 
lambds = np.array([ 2 * pow(math.sqrt(2), i + 1) for i in range(5)], dtype = 'float32') # range of lambda
sigmas = np.array([1.5,2.5]) # range de desviacion estandar
gamma = 1 
psis = np.array([0,np.pi/2], dtype = 'float32')

## Creacion de banco de gabor
gaborFilterBank0 = []
gaborFilterBank90 = []

gaborParams0 = []
gaborParams90 = []


## Agregando valores al banco de gabor
for theta in thetas:
    for lambd in lambds:
        for sigma in sigmas:
            gaborParam0 = {'ksize':(20, 20),'sigma':sigma,'theta':theta,
                          'lambd':lambd,'gamma':gamma,'psi':0,'ktype':cv2.CV_32F}
            gaborParam90 = {'ksize':(20, 20),'sigma':sigma,'theta':theta,
                          'lambd':lambd,'gamma':gamma,'psi':90,'ktype':cv2.CV_32F}
            
            Gabor0 = cv2.getGaborKernel(**gaborParam0)
            Gabor90 = cv2.getGaborKernel(**gaborParam90)
            
            gaborFilterBank0.append(Gabor0)
            gaborFilterBank90.append(Gabor90)
            
            gaborParams0.append(gaborParam0)
            gaborParams90.append(gaborParam90)

# Plot
"""print("Banco de funciones de Gabor para distintos angulos con psi = 0")
fig = plt.figure(1,figsize=(20,20))
n0 = len(gaborFilterBank0)
for i in range(n0):
    ang= gaborParams0[i]['theta'] / np.pi
    a = Fraction(ang)
    plt.subplot(4,n0//4, i+1)
    plt.title("{} $\pi$".format(a))
    plt.axis('off')
    plt.imshow(gaborFilterBank0[i],cmap='gray')

plt.show()"""

# Plot
"""print("Banco de funciones de Gabor para distintos angulos con psi = 90")
fig = plt.figure(1,figsize=(20,20))
n90 = len(gaborFilterBank90)
for i in range(n90):
    ang= gaborParams90[i]['theta'] / np.pi
    a = Fraction(ang)
    plt.subplot(4,n90//4, i+1)
    plt.title("{} $\pi$".format(a))
    plt.axis('off')
    plt.imshow(gaborFilterBank90[i],cmap='gray')

plt.show()"""

def EuclideanDistanceMatrix(M1,M2):
    shape = np.dot(M1,M2.T).shape
    result = np.zeros(shape,dtype = np.float32)
    
    for i in range(M1.shape[0]):
        for j in range(M2.shape[0]):
            a = M1[i,:] # vector fila
            b = M2[j,:] # Vector fila
            dist = np.linalg.norm(a-b)
            #dist = torch.norm(a - b) # escalar
            result[i,j] = dist   
    
    return result

def gabor_features(image,gaborFilterBank0,gaborFilterBank90):
    GaborFeatures = np.zeros((1,40),dtype = np.float32)
    
    for count,(mask0,mask90) in enumerate(zip(gaborFilterBank0,gaborFilterBank90)):

        #count = count + 1
        g0 = cv2.filter2D(image,-1,mask0)
        # convertir a tensor
        #g0_ = torch.from_numpy(g0).float().to(device)
        #g0 = pow(g0,2)

        g90 = cv2.filter2D(image,-1,mask90)
        # convertir a tensor
        #g90_ = torch.from_numpy(g90).float().to(device)
        #g90 = pow(g90,2)

        #g_T = math.sqrt(g0 +  g90)
        
        ### Distancia euclidiana entre 2 matrices 
        g_T = EuclideanDistanceMatrix(g0,g90)

        ### Valor de Gabor 
        suma = np.sum(g_T,axis = 0)
        suma = np.sum(suma)

        GaborFeatures[0,count] = suma  
        #count = count + 1
        
    return GaborFeatures

def glcm_features(image):
  GLCMFeatures = np.zeros((1,6),dtype = np.float32)

  dst = [1] 
  ang = [np.pi/2] # (np.pi/2 --> (dx =0 y dy = dst))

  ## Matriz GLCM nivel 1
  co_matriz_1 = greycomatrix(image, dst, ang).astype('uint8')
  co_matriz_1 = co_matriz_1[:,:,0,0]
  #print("O.o:",co_matriz_1.shape)

  ## Matriz GLCM nivel 2
  co_matriz_2 = greycomatrix(co_matriz_1, dst, ang).astype('uint8')
  #co_matriz_2 = co_matriz_2[:,:,0,0]

  # Indicadores 
  properties = ['ASM', 'correlation','contrast','dissimilarity','energy','homogeneity']

  ## Indicadores 
  """glcm = greycomatrix(co_matriz_2, distances = dst, angles = ang, 
                      symmetric = True,normed = True)"""

  for i,prop in enumerate(properties):
    GLCMFeatures[0,i] =  greycoprops(co_matriz_2, prop)
  
  #print(GLCMFeatures.shape)
  
  #GLCMFeatures[] = np.hstack([greycoprops(co_matriz_2, prop).ravel() for prop in properties])

  return GLCMFeatures

# Contenedores 
K = 369
N = 155
gab = 40 
glc = 6

Xgab = np.zeros((K*N,gab + glc)) # K x N muestras (filas), y Gab  características (columnas)
y = np.zeros((K*N),dtype ='int')
t = 0 

columns_gab = [ 'GAB' + str(i + 1) for i in range(gab)]
columns_glc = [ 'GLC' + str(i + 1) for i in range(glc)]

X = []
X.extend(columns_gab)
X.extend(columns_glc)

df = pd.DataFrame(Xgab, columns = X) 
dfy = pd.DataFrame(y,columns = ['clase'])

df = pd.concat([df, dfy], axis=1)

# Proceso en batch 
for i in tqdm(range(len(names))): 
  frames = utils.get_frames(in_dir, names[i])
  visible_frame = (frames*255).astype('uint8')
  for j in range(50, 130 + 1):
    img = visible_frame[j][:,:,2]
    img = cropped(img)
    #print(img.shape)
    example_gab = gabor_features(img,gaborFilterBank0,gaborFilterBank90)
    example_glc = glcm_features(img)
    if len(example_glc.shape) == 2:
      df.iloc[t,0:40]  = [i for i in example_gab[0]]
      df.iloc[t,40:46] = [i for i in example_glc[0]]
      df.iloc[t,46] =   labels[i][0]
      df.to_csv('./features_total.csv', index=False)
      #Xgab[t,:] = example
      t = t + 1
    else: 
      df.iloc[t,0:40]  = [0 for i in range(40)]
      df.iloc[t,40:46] = [0 for i in range(6)]
      df.iloc[t,46] =   labels[i][0]
      df.to_csv('./features_total.csv', index=False)
      t = t + 1